#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç»Ÿè®¡ 2016-11 å…¨æœˆè®¢å•åœ¨ç½‘æ ¼ä¸Šçš„æ—¶-ç©ºåˆ†å¸ƒï¼š
1. è¯»å– mapped_matrix_int.pklï¼ˆä»»æ„è¡ŒÃ—åˆ—ï¼Œä¾‹å¦‚ 18 Ã— 28 = 504ï¼‰
2. å°†è®¢å•æ˜ å°„åˆ° node_id
3. ä»¥ 10min Ã— node è®¡æ•°ï¼ŒæŒ‰å¤©å †å æ±‚æ¯æ§½çš„ Î¼, Ïƒ
4. ä¿å­˜ order_num_dist.pkl  (len=144ï¼Œæ¯æ§½ä¸€ä¸ª dict{node_id:[Î¼,Ïƒ]})
"""
import os, glob, math, tarfile, pickle, sys
from typing import Tuple

import numpy as np
import pandas as pd

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ è·¯å¾„ & å¸¸é‡ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
GLOB_PATTERN  = "../datasets/orders_information/2016_11*.csv"
MAPPED_PKL    = "../real_datasets/mapped_matrix_int.pkl"      # å¿…é¡»å·²ç”± 504 ç½‘æ ¼è„šæœ¬ç”Ÿæˆ
OUTPUT_PKL    = "../real_datasets/order_num_dist.pkl"

longitude_range = (102.989623, 104.896262)
latitude_range  = (30.090979,  31.437765)

RESAMPLE_FREQ   = "10min"   # 144 æ®µ/å¤©
REQ_COLS        = ['å¼€å§‹è®¡è´¹æ—¶é—´', 'ä¸Šè½¦ä½ç½®ç»åº¦', 'ä¸Šè½¦ä½ç½®çº¬åº¦']

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
def extract_csv(path: str) -> pd.DataFrame:
    """æ”¯æŒ .csv æˆ– .tar.gzï¼ˆåŽ‹ç¼©é‡Œç¬¬ä¸€å¼  csvï¼‰"""
    if path.endswith(".csv"):
        return pd.read_csv(path, usecols=REQ_COLS)

    if path.endswith((".tar.gz", ".tgz")):
        with tarfile.open(path, 'r:gz') as tar:
            member = next(m for m in tar.getmembers() if m.name.endswith('.csv'))
            with tar.extractfile(member) as f:
                return pd.read_csv(f, usecols=REQ_COLS)

    raise ValueError(f"æœªçŸ¥æ–‡ä»¶æ ¼å¼: {path}")


def map_orders_to_nodes(df: pd.DataFrame,
                        mapped_matrix: np.ndarray,
                        grid_size_lat: float,
                        grid_size_lon: float,
                        ) -> pd.DataFrame:
    """ç»çº¬åº¦ â†’ (row,col) â†’ node_idï¼Œè¿”å›žå« begin_time,node_id çš„ DataFrame"""
    n_rows, n_cols = mapped_matrix.shape
    x_idx = ((df['ä¸Šè½¦ä½ç½®ç»åº¦'] - longitude_range[0]) / grid_size_lon).astype(int)
    y_idx = ((df['ä¸Šè½¦ä½ç½®çº¬åº¦'] - latitude_range[0]) / grid_size_lat).astype(int)

    mask = (x_idx >= 0) & (x_idx < n_cols) & (y_idx >= 0) & (y_idx < n_rows)
    node_id = mapped_matrix[y_idx[mask], x_idx[mask]]

    df_valid = df.loc[mask, ['å¼€å§‹è®¡è´¹æ—¶é—´']].copy()
    df_valid['node_id'] = node_id
    df_valid['begin_time'] = pd.to_datetime(df_valid['å¼€å§‹è®¡è´¹æ—¶é—´'])
    return df_valid[['begin_time', 'node_id']]


def main():
    # 0. è½½å…¥ç½‘æ ¼æ˜ å°„çŸ©é˜µï¼Œè‡ªåŠ¨æŽ¨å¯¼ç½‘æ ¼è§’åº¦å®½åº¦
    with open(MAPPED_PKL, 'rb') as f:
        mapped_matrix = pickle.load(f)
    rows, cols     = mapped_matrix.shape
    grid_size_lat  = (latitude_range[1]  - latitude_range[0]) / rows
    grid_size_lon  = (longitude_range[1] - longitude_range[0]) / cols

    valid_node_ids = np.unique(mapped_matrix[mapped_matrix >= 0])
    print(f"ðŸ—º  ç½‘æ ¼å°ºå¯¸: {rows} Ã— {cols} = {rows*cols}ï¼ˆåº”ä¸º 504ï¼‰")
    print(f"â€ƒlat_step={grid_size_lat:.6f}Â°, lon_step={grid_size_lon:.6f}Â°")

    # 1. æ‰¾åˆ° 11 æœˆå…¨éƒ¨è®¢å•æ–‡ä»¶
    paths = sorted(glob.glob(GLOB_PATTERN))
    if not paths:
        print("âŒ æœªæ‰¾åˆ°è®¢å•æ–‡ä»¶"); sys.exit(1)
    print(f"å°†å¤„ç† {len(paths)} ä»½è®¢å•æ–‡ä»¶ â€¦")

    # ç´¯åŠ å™¨ï¼šnode_id â†’ [144 Ã— list[counts]]
    per_slot = {nid: [[] for _ in range(144)] for nid in valid_node_ids}

    # 2. é€æ–‡ä»¶ç»Ÿè®¡
    for k, path in enumerate(paths, 1):
        print(f"[{k:02d}/{len(paths)}] {os.path.basename(path)} â€¦", end="", flush=True)
        try:
            df_raw = extract_csv(path)
            df_map = map_orders_to_nodes(df_raw,
                                         mapped_matrix,
                                         grid_size_lat, grid_size_lon)
            # resample to 10-minute slots
            df_map = df_map.set_index('begin_time')
            grp    = df_map.groupby('node_id').resample(RESAMPLE_FREQ).size()
            counts = grp.unstack(fill_value=0)      # (node_id, 144)

            for nid, row in counts.iterrows():
                for t in range(144):
                    per_slot[nid][t].append(int(row.iloc[t]))
            print("âœ“")
        except Exception as e:
            print("âš ï¸  è·³è¿‡ï¼ŒåŽŸå› :", e)

    # 3. è®¡ç®— Î¼/Ïƒ
    order_num_dist: list[dict[int, list[float]]] = []
    for t in range(144):
        slot_dict = {}
        for nid in valid_node_ids:
            arr = np.array(per_slot[nid][t], dtype=float)
            if arr.size == 0:
                continue
            slot_dict[int(nid)] = [float(arr.mean()), float(arr.std(ddof=0))]
        order_num_dist.append(slot_dict)

    # 4. ä¿å­˜
    os.makedirs(os.path.dirname(OUTPUT_PKL), exist_ok=True)
    with open(OUTPUT_PKL, 'wb') as f:
        pickle.dump(order_num_dist, f)
    print(f"\nâœ… å·²ä¿å­˜åˆ° {OUTPUT_PKL} ï¼Œlen={len(order_num_dist)} (144 æ§½/å¤©)")

    # 5. æ‰“å°å‰å‡ è¡ŒéªŒç®—
    print("\n=== t=0 å‰ 6 ä¸ªç½‘æ ¼ Î¼/Ïƒ ç¤ºä¾‹ ===")
    for nid, ms in list(order_num_dist[0].items())[:100]:
        print(f"node {nid:>4}: Î¼={ms[0]:.2f}  Ïƒ={ms[1]:.2f}")


if __name__ == "__main__":
    main()
