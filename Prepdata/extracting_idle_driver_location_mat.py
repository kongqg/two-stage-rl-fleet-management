#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
build_idle_driver_location_mat_month.py
---------------------------------------
æ‰«æ 2016-11 å…¨æœˆå¸æœºè½¨è¿¹ (tar.gz)ï¼Œ
è®¡ç®—æ¯ 10-min Ã— ç½‘æ ¼çš„å¹³å‡ç©ºé—²å¸æœºæ•°ï¼Œ
ä¿å­˜ä¸º real_datasets/idle_driver_location_mat.pkl

â˜… è¯»å– mapped_matrix_int.pkl â†’ rows, cols
â˜… è‡ªåŠ¨æ¨å¯¼ grid_size_lat / grid_size_lon
â˜… å› æ­¤æ— éœ€æ‰‹æ”¹ä»»ä½•å¸¸é‡å³å¯å…¼å®¹ 18Ã—28ï¼504 æ ¼
"""
import os, tarfile, math, pickle, sys
from glob import glob
from typing import Tuple

import numpy as np
import pandas as pd

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ è·¯å¾„ & å‚æ•° â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
MONTH_PATTERN = "../datasets/drivers_information/2016_1101.tar.gz"
MAPPED_PKL    = "../real_datasets/mapped_matrix_int.pkl"
OUTPUT_PKL    = "../real_datasets/idle_driver_location_mat.pkl"
RESAMPLE_FREQ = "10min"          # 144 æ§½/æ—¥
REQ_COLS      = ['å¸æœºID','è®¢å•ID','GPSæ—¶é—´','è½¨è¿¹ç‚¹ç»åº¦','è½¨è¿¹ç‚¹çº¬åº¦']

# æˆéƒ½ bbox
longitude_range = (102.989623, 104.896262)
latitude_range  = (30.090979,  31.437765)

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
def load_grid() -> Tuple[np.ndarray, float, float]:
    """è¯»å–æ˜ å°„çŸ©é˜µï¼Œå¹¶è¿”è¿˜ç½‘æ ¼è§’åº¦æ­¥é•¿"""
    with open(MAPPED_PKL, 'rb') as f:
        mat = pickle.load(f)
    rows, cols = mat.shape
    gs_lat = (latitude_range[1]  - latitude_range[0]) / rows
    gs_lon = (longitude_range[1] - longitude_range[0]) / cols
    print(f"ğŸ—º  ç½‘æ ¼: {rows}Ã—{cols}={rows*cols}, "
          f"lat_step={gs_lat:.6f}Â°, lon_step={gs_lon:.6f}Â°")
    return mat, gs_lat, gs_lon


def extract_csv(tar_path: str) -> pd.DataFrame:
    """tar.gz â†’ DataFrame(REQ_COLS)"""
    with tarfile.open(tar_path, 'r:gz') as tar:
        member = next(m for m in tar.getmembers() if m.name.endswith('.csv'))
        with tar.extractfile(member) as f:
            return pd.read_csv(f, usecols=REQ_COLS)


def daily_idle_matrix(df: pd.DataFrame,
                      mapped: np.ndarray,
                      gs_lat: float,
                      gs_lon: float,
                      node2col: dict[int,int]) -> np.ndarray:
    """å•æ—¥ç©ºé—²çŸ©é˜µ (144, G)"""
    rows, cols = mapped.shape
    G = len(node2col)
    idle = np.zeros((144, G), int)

    # 1. æ—¶é—´é¢„å¤„ç†
    df['gps_time'] = pd.to_datetime(df['GPSæ—¶é—´'])

    intervals = (df.groupby(['å¸æœºID','è®¢å•ID'])['gps_time']
                   .agg(start='min', end='max')
                   .reset_index())
    day0 = intervals['start'].dt.floor('D').iloc[0]
    bins = pd.date_range(day0, periods=145, freq=RESAMPLE_FREQ)

    # 2. æ¯å¸æœº
    for drv_id, drv_traj in df.groupby('å¸æœºID'):
        busy = np.zeros(144, bool)
        for _, r in intervals[intervals['å¸æœºID']==drv_id].iterrows():
            i0 = np.searchsorted(bins, r.start, side='right')-1
            i1 = np.searchsorted(bins, r.end  , side='right')-1
            i0, i1 = max(i0,0), min(i1,143)
            if i1>=i0: busy[i0:i1+1] = True

        drv_traj = drv_traj.sort_values('gps_time')
        times = drv_traj['gps_time'].to_numpy('datetime64[ns]')

        for t in range(144):
            if busy[t]: continue
            ts = bins[t].to_datetime64()
            idx = np.argmin(np.abs(times - ts))
            lon, lat = drv_traj[['è½¨è¿¹ç‚¹ç»åº¦','è½¨è¿¹ç‚¹çº¬åº¦']].iloc[idx]

            x = int((lon - longitude_range[0]) / gs_lon)
            y = int((lat - latitude_range[0]) / gs_lat)
            if 0 <= x < cols and 0 <= y < rows:
                nid = mapped[y, x]
                if nid >= 0:
                    idle[t, node2col[nid]] += 1
    return idle


def main():
    mapped, gs_lat, gs_lon = load_grid()
    valid_nodes = np.unique(mapped[mapped >= 0])
    node2col = {nid:i for i, nid in enumerate(valid_nodes)}

    tar_paths = sorted(glob(MONTH_PATTERN))
    if not tar_paths:
        print("âŒ æ²¡æ‰¾åˆ°æ–‡ä»¶"); sys.exit(1)
    print(f"å…± {len(tar_paths)} ä¸ªæ—¥åŒ…ï¼Œå¼€å§‹å¤„ç† â€¦")

    sum_idle = np.zeros((144, len(valid_nodes)), float)
    for k, fp in enumerate(tar_paths, 1):
        print(f"[{k:02d}/{len(tar_paths)}] {os.path.basename(fp)} â€¦", end="", flush=True)
        try:
            df_day  = extract_csv(fp)
            idle_d  = daily_idle_matrix(df_day, mapped, gs_lat, gs_lon, node2col)
            sum_idle += idle_d
            print("âœ“")
        except Exception as e:
            print("âš ï¸  è·³è¿‡ï¼š", e)

    idle_avg = (sum_idle / len(tar_paths)).astype(np.float32)

    os.makedirs(os.path.dirname(OUTPUT_PKL), exist_ok=True)
    with open(OUTPUT_PKL, 'wb') as f:
        pickle.dump(idle_avg, f)
    print(f"\nâœ… å·²ä¿å­˜ {OUTPUT_PKL}  shape={idle_avg.shape}")

    # ç®€å•æ£€æŸ¥
    print("\nå‰ 3 æ§½å¹³å‡ç©ºé—²å¸æœºæ•°å‘é‡ï¼š")
    for t in range(3):
        print(f"slot {t:03d}", idle_avg[t])

if __name__ == "__main__":
    main()
